{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Libraries to be installed\n",
    "Some Sample commands\n",
    "conda create --name cs_sop\n",
    "source activate cs_sop\n",
    "conda install opencv\n",
    "conda install -c conda-forge tensorflow\n",
    "#for tensorflow 1.5 latest version\n",
    "pip install keras\n",
    "conda install h5py\n",
    "#for saving keras model\n",
    "conda install matplotlib\n",
    "pip install -U numpy\n",
    "#for latest version of numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0 2.1.5\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import io\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras\n",
    "import h5py\n",
    "print(tensorflow.__version__, keras.__version__)\n",
    "#install tensorflow above version 1.3 \n",
    "from keras import backend as K\n",
    "from keras.layers import (Conv2D, GlobalAveragePooling2D, Input, Lambda,\n",
    "                          MaxPooling2D)\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Flatten, Dense, Activation, Reshape\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_config_sections(config_file):\n",
    "    \"\"\"Convert all config sections to have unique names.\n",
    "    Adds unique suffixes to config sections for compability with configparser.\n",
    "    \"\"\"\n",
    "    section_counters = defaultdict(int)\n",
    "    output_stream = io.StringIO()\n",
    "    fin=config_file\n",
    "    newfilename='newconfig_file.cfg'\n",
    "    output_stream= open('newconfig_file.cfg','w')\n",
    "    for line in fin:\n",
    "        #print(line)\n",
    "        if line.startswith('['):\n",
    "            section = line.strip().strip('[]')\n",
    "            _section = section + '_' + str(section_counters[section])\n",
    "            section_counters[section] += 1\n",
    "            line = line.replace(section, _section)\n",
    "        output_stream.write(line)\n",
    "    output_stream.seek(0)\n",
    "    return newfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 416, 416, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 416, 416, 16)      432       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 416, 416, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 416, 416, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 208, 208, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 208, 208, 32)      4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 208, 208, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 208, 208, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 104, 104, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 104, 104, 64)      18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 104, 104, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 104, 104, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 52, 52, 128)       73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 52, 52, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 52, 52, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 256)       294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 13, 512)       1179648   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 13, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 1024)      4718592   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 1024)      9437184   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 13, 13, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 13, 13, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 125)       128125    \n",
      "=================================================================\n",
      "Total params: 15,867,885\n",
      "Trainable params: 15,861,773\n",
      "Non-trainable params: 6,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/cs_sop/lib/python3.6/site-packages/keras/models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "#m=createKerasmodel('yolo-small.cfg')\n",
    "##wrong model is being created by this method check this method later just load from existing model\n",
    "m=load_model('model_keras.h5')\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self,classes):\n",
    "        self.x, self.y = float(), float()\n",
    "        self.w, self.h = float(), float()\n",
    "        self.c = float()\n",
    "        self.class_num=classes\n",
    "        self.probs=np.zeros((classes,))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlap(x1,w1,x2,w2):\n",
    "    l1 = x1 - w1 / 2.;\n",
    "    l2 = x2 - w2 / 2.;\n",
    "    left = max(l1, l2)\n",
    "    r1 = x1 + w1 / 2.;\n",
    "    r2 = x2 + w2 / 2.;\n",
    "    right = min(r1, r2)\n",
    "    return right - left;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def box_intersection(ax,ay,aw,ah,bx,by,bw,bh):\n",
    "    w = overlap(ax, aw, bx, bw);\n",
    "    h = overlap(ay, ah, by, bh);\n",
    "    if w < 0 or h < 0: return 0;\n",
    "    area = w * h;\n",
    "    return area;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def box_union(ax,ay,aw,ah,bx,by,bw,bh):\n",
    "    i = box_intersection(ax,ay,aw,ah,bx,by,bw,bh);\n",
    "    u = aw * ah + bw * bh - i;\n",
    "    return u;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def box_iou(ax,ay,aw,ah,bx,by,bw,bh):\n",
    "    return box_intersection(ax,ay,aw,ah,bx,by,bw,bh) / box_union(ax,ay,aw,ah,bx,by,bw,bh);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NMS(final_probs , final_bbox):\n",
    "    '''\n",
    "    Function to perform non max suppresion of bounding boxes.\n",
    "    Eliminates all those boxes having iou>=0.4\n",
    "    '''\n",
    "    boxes=list()\n",
    "    indices=set()\n",
    "    pred_length = final_bbox.shape[0]\n",
    "    class_length = final_probs.shape[1]\n",
    "    for class_loop in range(class_length):\n",
    "        for index in range(pred_length):\n",
    "            if final_probs[index,class_loop] == 0: \n",
    "                continue\n",
    "            for index2 in range(index+1,pred_length):\n",
    "                if final_probs[index2,class_loop] == 0: \n",
    "                    continue\n",
    "                if index==index2 : continue\n",
    "                if box_iou(final_bbox[index,0],final_bbox[index,1],final_bbox[index,2],final_bbox[index,3],final_bbox[index2,0],final_bbox[index2,1],final_bbox[index2,2],final_bbox[index2,3]) >= 0.4:\n",
    "                    if final_probs[index2,class_loop] > final_probs[index, class_loop] :\n",
    "                        final_probs[index, class_loop] =0\n",
    "                        break\n",
    "                    final_probs[index2,class_loop]=0\n",
    "            \n",
    "            if index not in indices:\n",
    "                bb=BoundBox(class_length)\n",
    "                bb.x = final_bbox[index, 0]\n",
    "                bb.y = final_bbox[index, 1]\n",
    "                bb.w = final_bbox[index, 2]\n",
    "                bb.h = final_bbox[index, 3]\n",
    "              #  bb.c = final_bbox[index, 4]\n",
    "                bb.probs = np.asarray(final_probs[index,:])\n",
    "                boxes.append(bb)\n",
    "                indices.add(index)\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    #as given in the paper \n",
    "    return 1. / (1. + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def box_constructorv2(net_out_in,threshold):\n",
    "   \n",
    "    #hard- coded for yolov2-voc from config file\n",
    "    arr_max=0\n",
    "    sum=0\n",
    "    anchors = np.asarray([1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52])\n",
    "    boxes = list()\n",
    "    #wrong mostly\n",
    "    H, W, _ = [13,13,125]\n",
    "    #C = meta['classes']\n",
    "    C=20\n",
    "    B=5\n",
    "    #B = meta['num']\n",
    "    \n",
    "    #net_out_in.shape[2]=125\n",
    "    net_out = net_out_in.reshape([H, W, B, 125//B])\n",
    "    Classes = net_out[:, :, :, 5:]\n",
    "    Bbox_pred =  net_out[:, :, :, :5]\n",
    "    probs = np.zeros((H, W, B, C), dtype=np.float32)\n",
    "    \n",
    "    for row in range(H):\n",
    "        for col in range(W):\n",
    "            for box_loop in range(B):\n",
    "                arr_max=0\n",
    "                sum=0\n",
    "                Bbox_pred[row, col, box_loop, 4] = expit(Bbox_pred[row, col, box_loop, 4])\n",
    "                Bbox_pred[row, col, box_loop, 0] = (col + expit(Bbox_pred[row, col, box_loop, 0])) / W\n",
    "                Bbox_pred[row, col, box_loop, 1] = (row + expit(Bbox_pred[row, col, box_loop, 1])) / H\n",
    "                Bbox_pred[row, col, box_loop, 2] = np.exp(Bbox_pred[row, col, box_loop, 2]) * anchors[2 * box_loop + 0] / W\n",
    "                Bbox_pred[row, col, box_loop, 3] = np.exp(Bbox_pred[row, col, box_loop, 3]) * anchors[2 * box_loop + 1] / H\n",
    "                #SOFTMAX BLOCK, no more pointer juggling\n",
    "                for class_loop in range(C):\n",
    "                    arr_max=max(arr_max,Classes[row,col,box_loop,class_loop])\n",
    "                \n",
    "                for class_loop in range(C):\n",
    "                    Classes[row,col,box_loop,class_loop]=np.exp(Classes[row,col,box_loop,class_loop]-arr_max)\n",
    "                    sum+=Classes[row,col,box_loop,class_loop]\n",
    "                \n",
    "                for class_loop in range(C):\n",
    "                    tempc = Classes[row, col, box_loop, class_loop] * Bbox_pred[row, col, box_loop, 4]/sum                    \n",
    "                    if(tempc > threshold):\n",
    "                        probs[row, col, box_loop, class_loop] = tempc\n",
    "    \n",
    "    \n",
    "    #NMS- details of output vector postprocessing in paper-refer figure                   \n",
    "    return NMS(np.ascontiguousarray(probs).reshape(H*W*B,C), np.ascontiguousarray(Bbox_pred).reshape(H*B*W,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yolo_box_constructor(net_out,threshold):\n",
    "    con_file=open('yolov2-tiny-voc.cfg','r')\n",
    "    print('the net out received is')\n",
    "    print(net_out)\n",
    "    unique_config_file=unique_config_sections(con_file)\n",
    "    cfg_parser = configparser.ConfigParser()\n",
    "    cfg_parser.read(unique_config_file)\n",
    "    C=int (cfg_parser['region_0']['classes'])\n",
    "    \n",
    "    B=int (cfg_parser['region_0']['num'])\n",
    "    S=int(cfg_parser['region_0']['side'])\n",
    "    print(C,B,S)\n",
    "    sqrt=int (cfg_parser['detection_0']['sqrt'])+1\n",
    "    boxes=[]\n",
    "    count=0\n",
    "    SS=S*S\n",
    "    prob_size=SS*C\n",
    "    conf_size=SS*B\n",
    "    probs = np.ascontiguousarray(net_out[0 : prob_size]).reshape([SS,C])\n",
    "    print(probs)\n",
    "    confs =  np.ascontiguousarray(net_out[prob_size : (prob_size + conf_size)]).reshape([SS,B])\n",
    "    coords =  np.ascontiguousarray(net_out[(prob_size + conf_size) : ]).reshape([SS, B, 4])\n",
    "    final_probs = np.zeros([SS,B,C],dtype=np.float32)\n",
    "    for grid in range(SS):\n",
    "        for b in range(B):\n",
    "            coords[grid, b, 0] = (coords[grid, b, 0] + grid %  S) / S\n",
    "            coords[grid, b, 1] = (coords[grid, b, 1] + grid // S) / S\n",
    "            coords[grid, b, 2] =  coords[grid, b, 2] ** sqrt\n",
    "            coords[grid, b, 3] =  coords[grid, b, 3] ** sqrt\n",
    "            for class_loop in range(C):\n",
    "                #did not multiply by confidence measure\n",
    "                probs[grid, class_loop] = probs[grid, class_loop]*confs[grid, b]\n",
    "                print(\"PROBS\",probs[grid,class_loop])\n",
    "                if(probs[grid,class_loop] > threshold ):\n",
    "                    final_probs[grid, b, class_loop] = probs[grid, class_loop]*confs[grid, b]\n",
    "                    count+=1\n",
    "    \n",
    "    #changed to 5 \n",
    "    print('length of original no of boxes=',count)\n",
    "    return NMS(np.ascontiguousarray(final_probs).reshape(SS*B, C) , np.ascontiguousarray(coords).reshape(SS*B, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(620, 980, 3)\n",
      "(416, 416, 3) shape of resized\n",
      "(416, 416, 3)\n",
      "(1, 416, 416, 3)\n",
      "(1, 13, 13, 125)\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the image\n",
    "imagePath = 'test12.jpg'\n",
    "image = cv2.imread(imagePath)\n",
    "print (image.shape)\n",
    "#cv2.imshow('image',image)\n",
    "cv2.imwrite('imagechange.jpg',image)\n",
    "#f,(ax1,ax2) = plt.subplots(1,2,figsize=(16,6))\n",
    "#ax1.imshow(image)\n",
    "resized = cv2.resize(image,(416,416))\n",
    "print(resized.shape,'shape of resized')\n",
    "cv2.imwrite('resizedimage.jpg',resized)\n",
    "#resized=resized/255.0\n",
    "#check if we need to normalize the image\n",
    "print(resized.shape)\n",
    "\n",
    "imarray=resized/255.0\n",
    "\n",
    "#imarray=np.transpose(imarray)\n",
    "#imarray=imarray.reshape(416,416,3,-1)\n",
    "imarray=np.expand_dims(imarray,axis=0)\n",
    "\n",
    "print(imarray.shape)\n",
    "\n",
    "#print(imtrans.shape)\n",
    "out=m.predict(imarray)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13, 125)\n"
     ]
    }
   ],
   "source": [
    "print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_box(b,h,w,threshold):\n",
    "    max_indx=np.argmax(b.probs)\n",
    "    max_prob=b.probs[max_indx]\n",
    "    labels=['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
    "    label=labels[max_indx]\n",
    "    if max_prob > threshold:\n",
    "        left  = int ((b.x - b.w/2.) * w)\n",
    "        right = int ((b.x + b.w/2.) * w)\n",
    "        top   = int ((b.y - b.h/2.) * h)\n",
    "        bot   = int ((b.y + b.h/2.) * h)\n",
    "        if left  < 0    :  left = 0\n",
    "        if right > w - 1: right = w - 1\n",
    "        if top   < 0    :   top = 0\n",
    "        if bot   > h - 1:   bot = h - 1\n",
    "        mess = '{}'.format(label)\n",
    "        return (left, right, top, bot, mess, max_indx, max_prob)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_processing_out(net_out,original_im,threshold):\n",
    "    boxes=box_constructorv2(net_out,threshold)\n",
    "    print(len(boxes))\n",
    "    imgcv=cv2.imread(original_im)\n",
    "    img_name='outimage.jpg'\n",
    "    \n",
    "    colors=['red','red','red','red','red','blue','blue''blue','blue','blue','green','green','green','green','green','yellow','yellow','yellow','yellow','yellow']\n",
    "    h,w,_=imgcv.shape\n",
    "    print(imgcv.shape)\n",
    "    for b in boxes:\n",
    "        print('entering boxes')\n",
    "        boxResults=process_box(b,h,w,threshold)\n",
    "        if boxResults is None:\n",
    "            print('Box results is none')\n",
    "            continue\n",
    "        left,right,top,bot,mess,max_indx,confidence=boxResults\n",
    "        \n",
    "        thick=int((h+w)//300)\n",
    "        cv2.rectangle(imgcv,(left, top), (right, bot),(0,255,0), thick)\n",
    "        print(mess)\n",
    "        cv2.putText(imgcv, mess, (left, top - 12),0, 1e-3 * h, (0,255,0),thick // 3)\n",
    "    cv2.imwrite(img_name,imgcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(620, 980, 3)\n",
      "entering boxes\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "post_processing_out(out[0],'test12.jpg',0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:cs_sop]",
   "language": "python",
   "name": "conda-env-cs_sop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
